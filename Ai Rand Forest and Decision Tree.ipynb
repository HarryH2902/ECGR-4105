{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d809ef-499e-4da9-bae7-a9827ad43582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Debugging help\n",
    "NUM_COMPANIES = 500                    # Set to 500 for full run\n",
    "FORCE_REDOWNLOAD = True               # Set to False if the spreadsheets are downloaded and current, stops the program from re-downloading the spreadsheets\n",
    "SAVE_DIR = \"data\"\n",
    "FUNDAMENTAL_DIR = \"fundamentals\"\n",
    "\n",
    "# Get S&P tickers\n",
    "def get_sp500_tickers():\n",
    "    url = \"https://datahub.io/core/s-and-p-500-companies/r/constituents.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "    return df['Symbol'].str.replace('.', '-', regex=False).tolist()\n",
    "\n",
    "# Download the data\n",
    "def download_stock_data(tickers, start=\"2000-01-01\", end=None, save_dir=SAVE_DIR, force_redownload=False):\n",
    "    if end is None:\n",
    "        end = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(FUNDAMENTAL_DIR, exist_ok=True)\n",
    "    data = {}\n",
    "\n",
    "    for i, ticker in enumerate(tickers):\n",
    "        file_path = os.path.join(save_dir, f\"{ticker}.csv\")\n",
    "        fundamentals_path = os.path.join(FUNDAMENTAL_DIR, f\"{ticker}_fundamentals.csv\")\n",
    "\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            if os.path.exists(file_path) and not force_redownload:\n",
    "                df = pd.read_csv(file_path)\n",
    "                if 'Date' not in df.columns or 'Close' not in df.columns:\n",
    "                    continue\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                df.set_index('Date', inplace=True)\n",
    "            else:\n",
    "                df = stock.history(start=start, end=end, auto_adjust=False)\n",
    "                if df.empty or len(df) < 200:\n",
    "                    continue\n",
    "                df.reset_index(inplace=True)\n",
    "                df.to_csv(file_path, index=False)\n",
    "                df.set_index('Date', inplace=True)\n",
    "\n",
    "            info = stock.info\n",
    "            new_row = {\n",
    "                'Date': datetime.today().strftime(\"%Y-%m-%d\"),\n",
    "                'Ticker': ticker,\n",
    "                'peRatio': info.get('trailingPE', np.nan),\n",
    "                'pegRatio': info.get('pegRatio', np.nan),\n",
    "                'priceToSales': info.get('priceToSalesTrailing12Months', np.nan),\n",
    "                'priceToBook': info.get('priceToBook', np.nan),\n",
    "                'debtToEquity': info.get('debtToEquity', np.nan),\n",
    "                'ebitda': info.get('ebitda', np.nan)\n",
    "            }\n",
    "\n",
    "            if os.path.exists(fundamentals_path):\n",
    "                existing = pd.read_csv(fundamentals_path)\n",
    "                if not ((existing['Date'] == new_row['Date']) & (existing['Ticker'] == new_row['Ticker'])).any():\n",
    "                    updated = pd.concat([existing, pd.DataFrame([new_row])], ignore_index=True)\n",
    "                    updated.to_csv(fundamentals_path, index=False)\n",
    "            else:\n",
    "                pd.DataFrame([new_row]).to_csv(fundamentals_path, index=False)\n",
    "\n",
    "            df['Ticker'] = ticker\n",
    "            data[ticker] = df\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {ticker}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Preprocess for training\n",
    "def preprocess_data(data):\n",
    "    frames = []\n",
    "    for ticker, df in data.items():\n",
    "        try:\n",
    "            if 'Close' not in df.columns:\n",
    "                raise ValueError(f\"Missing Close column, shape: {df.shape}\")\n",
    "\n",
    "            df = df[['Open', 'High', 'Low', 'Volume', 'Close']].copy()\n",
    "            df['Lag_Close'] = df['Close'].shift(1)\n",
    "            df['Lag_1'] = df['Close'].shift(1)\n",
    "            df['MA_5'] = df['Close'].rolling(5).mean()\n",
    "            df['Return'] = df['Close'].pct_change()\n",
    "            df['Target'] = df['Close'].shift(-5)\n",
    "            df.dropna(inplace=True)\n",
    "\n",
    "            if len(df) < 10:\n",
    "                continue\n",
    "\n",
    "            fund_file = os.path.join(FUNDAMENTAL_DIR, f\"{ticker}_fundamentals.csv\")\n",
    "            if not os.path.exists(fund_file):\n",
    "                continue\n",
    "\n",
    "            row = pd.read_csv(fund_file).sort_values('Date').iloc[-1]\n",
    "            for col in ['peRatio', 'pegRatio', 'priceToSales', 'priceToBook', 'debtToEquity', 'ebitda']:\n",
    "                df[col] = row.get(col, np.nan)\n",
    "\n",
    "            df['Ticker'] = ticker\n",
    "            frames.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Preprocessing error on {ticker}: {e}\")\n",
    "\n",
    "    if not frames:\n",
    "        raise ValueError(\"All tickers failed during preprocessing.\")\n",
    "\n",
    "    result = pd.concat(frames)\n",
    "    result.reset_index(inplace=True)\n",
    "    return result\n",
    "\n",
    "# Extract features and labels\n",
    "def prepare_features(df):\n",
    "    y = df['Target']\n",
    "    X = df.drop(columns=['Target'])\n",
    "    non_numeric_cols = X.select_dtypes(include=['object', 'datetime64']).columns.tolist()\n",
    "    for col in ['Date', 'Datetime']:\n",
    "        if col in X.columns:\n",
    "            non_numeric_cols.append(col)\n",
    "    X.drop(columns=list(set(non_numeric_cols)), inplace=True)\n",
    "    le = LabelEncoder()\n",
    "    if 'Ticker' in df.columns:\n",
    "        X['Ticker'] = le.fit_transform(df['Ticker'])\n",
    "    return X, y\n",
    "\n",
    "# Train and evaluate\n",
    "def train_and_evaluate(X, y, model_name=\"RandomForest\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)\n",
    "    if model_name == \"RandomForest\":\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=1)\n",
    "    elif model_name == \"DecisionTree\":\n",
    "        model = DecisionTreeRegressor(random_state=1)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    return model, X_test.index, y_test, preds, rmse, r2\n",
    "\n",
    "# Plot predictions\n",
    "def plot_predictions(index, y_true, rf_pred, dt_pred):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(index, y_true, label='Actual', linewidth=2)\n",
    "    plt.plot(index, rf_pred, label='Random Forest', alpha=0.7)\n",
    "    plt.title(\"Random Forest Predictions vs Actual\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(index, y_true, label='Actual', linewidth=2)\n",
    "    plt.plot(index, dt_pred, label='Decision Tree', alpha=0.7)\n",
    "    plt.title(\"Decision Tree Predictions vs Actual\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importances\n",
    "def plot_feature_importances(model, X, title):\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        raise ValueError(\"Model does not support feature importances.\")\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=importances[indices], y=np.array(X.columns)[indices])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return importances\n",
    "\n",
    "# Main Prog\n",
    "tickers = get_sp500_tickers()[:NUM_COMPANIES]\n",
    "stock_data = download_stock_data(tickers, force_redownload=FORCE_REDOWNLOAD)\n",
    "processed = preprocess_data(stock_data)\n",
    "X, y = prepare_features(processed)\n",
    "\n",
    "rf_model, rf_index, rf_y, rf_pred, rf_rmse, rf_r2 = train_and_evaluate(X, y, model_name=\"RandomForest\")\n",
    "dt_model, dt_index, dt_y, dt_pred, dt_rmse, dt_r2 = train_and_evaluate(X, y, model_name=\"DecisionTree\")\n",
    "\n",
    "plot_predictions(rf_index, rf_y, rf_pred, dt_pred)\n",
    "rf_importances = plot_feature_importances(rf_model, X, \"Random Forest Feature Importances\")\n",
    "dt_importances = plot_feature_importances(dt_model, X, \"Decision Tree Feature Importances\")\n",
    "\n",
    "print(f\"\\nRandom Forest: RMSE = {rf_rmse:.2f}, R2 Score = {rf_r2:.4f}\")\n",
    "print(f\"Decision Tree: RMSE = {dt_rmse:.2f}, R2 Score = {dt_r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
